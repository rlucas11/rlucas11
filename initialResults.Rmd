---
title: "Item-Order Replication"
subtitle: "Initial Results After First Pre-registered Study"
author: "Richard E. Lucas, Carol Tweten, and Felix Cheung"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: default
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
bibliography: "~/Dropbox/MyLibraryZ2.bib"
link-citations: yes
---

```{r setup, include=FALSE}
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```

# Introduction

The goal of this pre-registered project is to replicate and extend a result by @Deaton2011Se, who found that asking questions about politics before asking about subjective well-being led to lower levels of well-being than if the political questions had not been asked. The study was important because it was one of the few large-sample studies showing moderate context effects on well-being judgments [see @lucas_what_2016] and it contradicted one prior meta-analysis of item-order effects [@Schimmack2005JoPaSP]. In a commentary, Lucas et al. suggested one explanation for why the effect emerged in this study, even though it had been shown to be weak in prior studies. Specifically, we argued that the specific context of the survey (a political survey by the polling company Gallup) may have influenced respondents' interpretation of the specific well-being question that was asked (the "Ladder" question that is typically used by Gallup). Participants may have interpreted this ladder question as being an additional question about their overall satisfaction with government and its effects on their lives. Evidence for this hypothesis comes from prior studies that have found very weak item-order effects (Schimmack & Oishi, 2005), and from the fact that asking a simple question about life satisfaction (one that explicitly mentioned respondents' "personal life") between the political questions and the ladder measure eliminated the item-order effect, a finding that ruled out simpler mood or information accessibility explanations. 

Thus, we proposed a study with three conditions. In the control condition, participants were first asked about their well-being and then about their political views. In a second condition that we believed was similar to the types of studies tested by Schimmack and Oishi (2005), we asked the same three political questions as in the original study, but presented the study as a study on student life and opinions. In the final version, we presented the study as a study of political opinions and asked a variety of questions about voting behavior. We predicted there to be significantly different well-being ratings when comparing the control to politics-salient condition, but not when comparing control to the student-life condition. We also expected the effects to be larger for the Ladder question used in the original study as compared to a standard life satisfaction question. This prediction was made based on the fact that Deaton (2012) actually used a life satisfaction question as a "buffer" question that eliminated the effects of political questions on the Ladder. Ideally, we would have manipulated the order of these questions, but we wanted to have as much power as possible to detect the primary effects of interest. We also tested whether the correlation between the political questions and the well-being measures varied depending on condition. Deaton (2012) did not examine these correlations, but prior investigations of item-order effects did [@Strack1988EJoSP]. Finally, we expected correlations between the two well-being measures and additional outcomes assessed towards the end of the survey *not* to vary across conditions, as we did not expect validity to be impacted, even when the manipulation was successful. 

The preregistration form for this study is available [here](https://osf.io/fvkua/). Full materials are available [here](https://osf.io/jj97v/). 



# Mean Differences Across Conditions


```{r echo=FALSE, message=FALSE, warning=FALSE}
## Load packages
library(car)
library(ggplot2)
library(tidyr)
library(ez)
library(tidyr)
library(psych)
library(dplyr)
library(compute.es)

## Read Data
data <- read.csv("../data/final.csv")
data$Condition <- as.factor(data$Condition)
```


The table below shows means and standard deviations for the three conditions. Plots of the distributions across conditions are shown in the margin. 

```{r echo=FALSE}
## Means

condMeans <- data %>%
    group_by(Condition) %>%
    summarise(Mean.LS = mean(LSR, na.rm=TRUE),
              SD.LS = sd(LSR, na.rm=TRUE),
              Mean.Ladder = mean(LadderR, na.rm=TRUE),
              SD.Ladder = sd(LadderR, na.rm=TRUE),
              n.LS = sum(!is.na(LSR)),
              n.Ladder = sum(!is.na(LadderR)))
condMeans[,1] <- c("Politics Salient", "Student Life", "Control")

knitr::kable(
           condMeans,
           caption = 'Means and Standard Deviations by Condition',
           digits = 2,
           col.names = c("Condition", "LS Mean", "LS SD", "Ladder Mean", "Ladder SD",
                         "LS N", "Ladder N")
       )

computeD <- function(table, r1, r2, var) {
    var.mean <- paste("Mean", var, sep=".")
    var.sd <- paste("SD", var, sep=".")
    var.n <- paste("n", var, sep=".")
    compute.es::mes(m.1=condMeans[[r1,var.mean]], m.2=condMeans[[r2,var.mean]],
    sd.1=condMeans[[r1,var.sd]], sd.2=condMeans[[r2,var.sd]],
    n.1=condMeans[[r1,var.n]], n.2=condMeans[[r2,var.n]], verbose=FALSE)
}

dPolLS <- computeD(condMeans, 1, 3, "LS")$d 
dStuLS <- computeD(condMeans, 2, 3, "LS")$d 
dPolLad <- computeD(condMeans, 1, 3, "Ladder")$d 
dStuLad <- computeD(condMeans, 2, 3, "Ladder")$d 

```

```{r fig.margin=TRUE, fig.cap = "Life Satisfaction by Condition", fig.width=3.5, fig.height=3.5, cache=TRUE, message=FALSE, echo=FALSE}

p2 <- ggplot(data, aes(x=Condition, y=LSR)) +
    geom_violin()
p2 + geom_boxplot(width=.1) +
    scale_y_continuous(breaks=0:10,limits=c(0,10)) +
    stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="red")
```

```{r fig.margin=TRUE, fig.cap = "Ladder Scores by Condition", fig.width=3.5, fig.height=3.5, cache=TRUE, message=FALSE, echo=FALSE}

p <- ggplot(data, aes(x=Condition, y=LadderR)) +
    geom_violin()
p + geom_boxplot(width=.1) +
    scale_y_continuous(breaks=0:10,limits=c(0,10)) +
    stat_summary(fun.y=mean, geom="point", shape=23, size=2, color="red")
```

```{r echo=FALSE}

lTestLS <- leveneTest(LSR ~ Condition, data=data)
lTestLadder <- leveneTest(LadderR ~ Condition, data=data)

```

Levene's test for homogeneity of variances was examined and was not significant either for life satisfaction, $`r paste0("F (", lTestLS$Df[1], ", ", lTestLS$Df[2], ") = ", round(lTestLS$F[1], 2), ", n.s.")`$, or ladder scores $`r paste0("F (", lTestLadder$Df[1], ", ", lTestLadder$Df[2], ") = ", round(lTestLadder$F[1], 2), ", n.s.")`$ One-way ANOVAs showed that the effect of condition was significant for life satisfaction but not for ladder scores. Preregistered planned contrasts comparing each condition to the control condition are presented in the tables below.

```{r echo=FALSE}

c1 <- c(0,1,-1)
c2 <- c(1,0,-1)
mat <- cbind(c1,c2)
contrasts(data$Condition) <- mat

fit <- aov(LadderR ~ Condition, data=data)
cTableLadder <- summary.aov(fit, split=list(Condition=list("Student Issues vs. Control"=1,
                                           "Politics Salient vs. Control"=2)))
fitLS <- aov(LSR ~ Condition, data=data)
cTableLS <- summary.aov(fitLS, split=list(Condition=list("Student Issues vs. Control"=1,
                                           "Politics Salient vs. Control"=2)))

knitr::kable(xtable::xtable(

    cTableLS,
    digits = 2
    
    ), digits = 3
)

knitr::kable(xtable::xtable(
    cTableLadder,
    digits = 2
    ), digits = 3
)


```

For life satisfaction, consistent both with the original study and our predictions, the difference in scores is largest between the control condition and the condition in which the political nature of the survey was made salient (*d =* `r dPolLS`, compared to *d =* `r dStuLS` for the student issues condition). This contrast for the politics-salient condition is significant. The contrast for the student-issues condition is not significant, though the effect size is positive and not that different than that from the politics-salient condition. It is important to note, however, that the direction of these effects are opposite to what is reported in the original study, where the inclusion of political questions led to lower well-being. For the ladder measure, the differences across condition were smaller (*d =* `r dPolLad` and `r dStuLad` for the politics and student-issues conditions, respectively) and not significant. 

```{r echo = FALSE, warning = FALSE}
dataLong <- data %>% gather(Measure, score, LadderR, LSR)

rmLadder <- ezANOVA(data=dataLong,
                    dv=score,
                    wid=ID,
                    between=Condition,
                    within=Measure)
```


## Repeated-Measures ANOVA

As specified in our preregistered analytic plan, we conducted a repeated measures ANOVA with condition as a between-persons factor and measure (life satisfaction vs. ladder) as a within-persons factor. This analysis test whether the effect of condition differs by measure; our prediction was that the ladder measure would be more affected by condition than would the life satisfaction measure. The means presented above point in the opposite direction (with larger differences for life satisfaction than for the ladder measure), but the repeated measures ANOVA showed that the differences across measures were not significant (though power to detect such differences may not have been high). 


```{r echo = FALSE, warning = FALSE}

knitr::kable(
  rmLadder$ANOVA,
  digits = 3,
  row.names = FALSE
)  

```

# Correlations

Early studies looking at the effect of preceding questions on later outcomes typically focused on the correlation between responses to the two questions depending on the order in which they were presented (see Schimmack and Oishi, 2005, for a review). Although Deaton (2012) did not focus on these correlations, it is also possible to examine them in this study. Specifically, if asking political questions before well-being questions increases the likelihood that opinions on political issues are used in well-being judgments, then the correlation should be stronger when the political questions are asked prior to the well-being questions. Thus, we can examine correlations across conditions. The table below shows the correlation between life satisfaction and each of the three "approval" questions (for Congress, President Obama, and the state of the country) for each of the three conditions ^[The sample size for the third item, satisfaction with how the country is going, has a smaller sample size because an "unsure" option was provided, and this was treated as missing.]. The columns labeled "rtest" show the *Z*-test for independent correlations, comparing across pairs of conditions. As can be seen in this table (and consistent with Schimmack and Oishi), none of the correlations are significantly different from one another (though power to detect small differences was not high), and the pattern of differences is not consistent across measures. 


``` {r echo = FALSE, warning = FALSE}

compareCors <- function(df, group, v1, v2) {
    nLevels <- length(levels(df[,group]))
    results <- as.data.frame(matrix(NA, nrow=nLevels, ncol=(2 + (nLevels - 1))))
    for (i in 1:nLevels) {
        lev <- levels(df[,group])[i]
        selectDf <- df[which(df[,group]==lev),]
        results[i, 1] <- cor(selectDf[,c(v1, v2)], use="pair")[1, 2]
        results[i, 2] <- sum(!is.na(selectDf[,v1])&!is.na(selectDf[,v2]))
    }
    for (i in 1:(nLevels-1)) {
        for (j in (i+1):nLevels) {
            results[j, 2+i] <- psych::r.test(n=results[[i,2]],
                                            r12=results[[i,1]],
                                            r34=results[[j,1]],
                                            n2=results[[j,2]])$z
        }
    }
    names(results) <- c("r", "n", paste0("rtest", 1:(nLevels-1)))
    return(results)
}

a1 <- compareCors(data, "Condition", "LSR", "approve1R")
a2 <- compareCors(data, "Condition", "LSR", "approve2R")
a3 <- compareCors(data, "Condition", "LSR", "approve3R")

comboTable <- cbind(a1, a2, a3)
row.names(comboTable) = c("Politics Salient", "Student Life", "Control")
options(knitr.kable.NA = '')
knitr::kable(
           comboTable,
           digits = 3
       )


```

The next table shows similar results for correlations between the ladder measure and each approval item. Again, the pattern of differences is inconsistent, and with one exception, correlations are not significantly different across conditions. Thus, only 1 out of 18 differences tested was significantly different from zero, supporting Schimmack and Oishi's contention that item-order effects are not large when correlations between items are used as outcomes. 

```{r echo = FALSE}

a1 <- compareCors(data, "Condition", "LadderR", "approve1R")
a2 <- compareCors(data, "Condition", "LadderR", "approve2R")
a3 <- compareCors(data, "Condition", "LadderR", "approve3R")

comboTable <- cbind(a1, a2, a3)
row.names(comboTable) = c("Politics Salient", "Student Life", "Control")
options(knitr.kable.NA = '')
knitr::kable(
           comboTable,
           digits = 3
       )


```



# Correlations With Other Measures

A final goal was to examine the correlations between each well-being measure and other conceptually related constructs that were assessed after the politics questions had been presented in the control condition. Specifically, we examined the associations between these variables and measures of personality, along with a more standard, multiple-item measure of life satisfaction (the SWLS; @Diener1985JoPA) and measures of affect. One expectation would be that in the conditions in which political content was made salient, correlations with other criteria would be lower than when this content was not made salient. The tables below report the correlations between the single-item life satisfaction measure that was the focus of this investigation and each of the criterion measures. As can be seen in these tables, this prediction is not borne out by the data. Four differences are significant. Three of these involve differences between life satisfaction and other well-being measures in the control condition versus the that in the student-life condition. This suggests that the correlation between the various well-being measures is actually weaker when the political opinions are not made salient as compared to the conditions where they are (though only the difference with "student-life" is significant). The final significant difference is more difficult to interpret, as it is between two of the experimental conditions. 


```{r echo = FALSE}

a1 <- compareCors(data, "Condition", "LSR", "swls")
a2 <- compareCors(data, "Condition", "LSR", "E_mean")
a3 <- compareCors(data, "Condition", "LSR", "A_mean")
a4 <- compareCors(data, "Condition", "LSR", "C_mean")
a5 <- compareCors(data, "Condition", "LSR", "N_mean")
a6 <- compareCors(data, "Condition", "LSR", "O_mean")
a7 <- compareCors(data, "Condition", "LSR", "pa")
a8 <- compareCors(data, "Condition", "LSR", "na")

row.names(a1) = c("Politics Salient", "Student Life", "Control")
row.names(a2) = c("Politics Salient", "Student Life", "Control")
row.names(a3) = c("Politics Salient", "Student Life", "Control")
row.names(a4) = c("Politics Salient", "Student Life", "Control")
row.names(a5) = c("Politics Salient", "Student Life", "Control")
row.names(a6) = c("Politics Salient", "Student Life", "Control")
row.names(a7) = c("Politics Salient", "Student Life", "Control")
row.names(a8) = c("Politics Salient", "Student Life", "Control")


options(knitr.kable.NA = '')

knitr::kable(
           a1,
           digits = 3,
           caption = "Correlations between Life Satisfaction and SWLS"
       )

knitr::kable(
           a7,
           digits = 3,
           caption = "Correlations between Life Satisfaction and Positive Affect"
       )

knitr::kable(
           a8,
           digits = 3,
           caption = "Correlations between Life Satisfaction and Negative Affect"
       )


knitr::kable(
           a2,
           digits = 3,
           caption = "Correlations between Life Satisfaction and Extraversion"
       )

knitr::kable(
           a3,
           digits = 3,
           caption = "Correlations between Life Satisfaction and Agreeableness"
       )

knitr::kable(
           a4,
           digits = 3,
           caption = "Correlations between Life Satisfaction and Conscientiousness"
       )

knitr::kable(
           a5,
           digits = 3,
           caption = "Correlations between Life Satisfaction and Neuroticism"
       )

knitr::kable(
           a6,
           digits = 3,
           caption = "Correlations between Life Satisfaction and Openness"
       )


```

The next set of tables reports the same results for the ladder measure. With this measure, none of the differences are significant. Thus, it appears that the validity of the well-being items is not affected by the presentation of political questions. 



```{r echo = FALSE}

a1 <- compareCors(data, "Condition", "LadderR", "swls")
a2 <- compareCors(data, "Condition", "LadderR", "E_mean")
a3 <- compareCors(data, "Condition", "LadderR", "A_mean")
a4 <- compareCors(data, "Condition", "LadderR", "C_mean")
a5 <- compareCors(data, "Condition", "LadderR", "N_mean")
a6 <- compareCors(data, "Condition", "LadderR", "O_mean")
a7 <- compareCors(data, "Condition", "LadderR", "pa")
a8 <- compareCors(data, "Condition", "LadderR", "na")

row.names(a1) = c("Politics Salient", "Student Life", "Control")
row.names(a2) = c("Politics Salient", "Student Life", "Control")
row.names(a3) = c("Politics Salient", "Student Life", "Control")
row.names(a4) = c("Politics Salient", "Student Life", "Control")
row.names(a5) = c("Politics Salient", "Student Life", "Control")
row.names(a6) = c("Politics Salient", "Student Life", "Control")
row.names(a7) = c("Politics Salient", "Student Life", "Control")
row.names(a8) = c("Politics Salient", "Student Life", "Control")


options(knitr.kable.NA = '')

knitr::kable(
           a1,
           digits = 3,
           caption = "Correlations between Ladder and SWLS"
       )


knitr::kable(
           a7,
           digits = 3,
           caption = "Correlations between Ladder and Positive Affect"
       )

knitr::kable(
           a8,
           digits = 3,
           caption = "Correlations between Ladder and Negative Affect"
       )


knitr::kable(
           a2,
           digits = 3,
           caption = "Correlations between Ladder and Extraversion"
       )

knitr::kable(
           a3,
           digits = 3,
           caption = "Correlations between Ladder and Agreeableness"
       )

knitr::kable(
           a4,
           digits = 3,
           caption = "Correlations between Ladder and Conscientiousness"
       )

knitr::kable(
           a5,
           digits = 3,
           caption = "Correlations between Ladder and Neuroticism"
       )

knitr::kable(
           a6,
           digits = 3,
           caption = "Correlations between Ladder and Openness"
       )


```

The results varied by measure, with significantly different correlations only found for life satisfaction, but not for the ladder. One possible explanation (though admittedly post hoc) is that in the two politics-first conditions, both the primary outcome measures (life satisfaction and ladder) and the relevant criteria (the SWLS and affect measures) come after the introduction of the political questions. If the content from these questions consistently affected all well-being measures, then this could lead to artificially high correlations. The control condition introduced the political questions between the primary outcomes and the assessed criteria, which could reduce correlations between them. However, this explanation does not account for the fact that the effects primarily emerged for life satisfaction but not the ladder measure, even though these two items were assessed back to back. However, future studies could manipulate when, in the control condition, the political items are assessed. 

#Exploratory Analyses

The main finding from the above analysis was that those individuals who were assigned to the "politics-salient" condition reported higher levels of subjective well-being than those in the control condition. The differences for the "student-life" condition were not significant. However, as noted above, the direction of this effect was opposite to that found by Deaton (2012), were ladder scores were lower after participants completed political questions. 

One possible explanation for this discrepancy concerns the sample and the political context. This study took place in the week before the 2016 presidential election in a sample of college students. Because (as we report below) the majority of participants supported Hilary Clinton for president, and because polls suggested that Clinton would win the election, it is possible that reminding participants about politics elicited some amount of optimism and positive feeling in this sample at this time. If so, we would expect the effect to be most positive among Clinton supporters, but less positive among others. Thus, we looked at the interaction between being a Clinton supporter and the manipulation when predicting the two well-being measures. 

```{r echo=FALSE}
clintonLS <- aov(LSR ~ Condition * clinton, data=data)
knitr::kable(summary(clintonLS)[[1]], digits=3, caption="ANOVA Table for Life Satisfacton")

clinton <- aov(LadderR ~ Condition * clinton, data=data)
knitr::kable(summary(clinton)[[1]], digits=3, caption="ANOVA Table for Ladder Scores")
```

The results in the table above show that there was not a significant interaction between condition and support for Clinton in either life satisfaction or ladder measures. Means for all variables across conditions are presented below. 

```{r echo=FALSE}

condMeans <- data %>%
    group_by(Condition, clinton) %>%
    summarise(Mean.LS = mean(LSR, na.rm=TRUE),
              SD.LS = sd(LSR, na.rm=TRUE),
              Mean.Ladder = mean(LadderR, na.rm=TRUE),
              SD.Ladder = sd(LadderR, na.rm=TRUE))


condMeans1 <- condMeans[which(condMeans$clinton==0),]
condMeans2 <- condMeans[which(condMeans$clinton==1),]
clintonTable <- cbind(condMeans1,condMeans2)
clintonTable[,1] <- c("Politics Salient", "Student Life", "Control")
clintonTable[,c(2,7,8)] <- NULL

knitr::kable(clintonTable, digits=2)



```


# Failure of Randomization?

As a final (exploratory) check, we examined means for variables assessed towards the end of the survey, including variables that, theoretically, should not be affected by the manipulation included at the beginning of the study. The results below show of the six variables we looked at, two (neuroticism and conscientiousness) showed significant differences across conditions, and a third (the Satisfaction With Life Scale) had differences across conditions that were moderate in size (though non-significant). 

```{r echo=FALSE}
knitr::kable(summary(swlsAov <- aov(swls ~ Condition, data=data))[[1]], digits=3, caption="ANOVA Table for SWLS")
knitr::kable(summary(EAov <- aov(E_mean ~ Condition, data=data))[[1]], digits=3, caption="ANOVA Table for Extraversion")
knitr::kable(summary(AAov <- aov(A_mean ~ Condition, data=data))[[1]], digits=3, caption="ANOVA Table for Agreeableness")
knitr::kable(summary(CAov <- aov(C_mean ~ Condition, data=data))[[1]], digits=3, caption="ANOVA Table for Conscientiousness")
knitr::kable(summary(NAov <- aov(N_mean ~ Condition, data=data))[[1]], digits=3, caption="ANOVA Table for Neuroticism")
knitr::kable(summary(OAov <- aov(O_mean ~ Condition, data=data))[[1]], digits=3, caption="ANOVA Table for Openness")

```


The means for the three variables noted above are provided in the table below:

```{r echo=FALSE}

condMeansP <- data %>%
    group_by(Condition) %>%
    summarise(Mean.swls = mean(swls, na.rm=TRUE),
              SD.swls = sd(swls, na.rm=TRUE),
              Mean.C_mean= mean(C_mean, na.rm=TRUE),
              SD.C_mean= sd(C_mean, na.rm=TRUE),
              Mean.N_mean= mean(N_mean, na.rm=TRUE),
              SD.N_mean= sd(N_mean, na.rm=TRUE))

condMeansP[,1] <- c("Politics Salient", "Student Life", "Control")

knitr::kable(condMeansP, digits=2, caption="Effect of Manipulation on Means for SWLS, Conscientiousness, and Neuroticism")


```

Importantly, although these differences could potentially be due to the manipulation, this explanation is not especially plausible, both because it is unclear why conscientiousness or neuroticism would be impacted by the presentation of political questions, and because the effects of the manipulation would presumably have worn off by this point in the study. In any case, these unpredicted differences mean that replication of the primary results is desirable.

# Preregistered Replication

One interpretation of the difference in results from our study to the original study it replicates is that the historical context affected the direction of the effect that making politics salient had on life satisfaction judgments. Because the election did not turn out as polls predicted, this historical context will now be different if we rerun the study after the election. Thus, we plan to preregister a new study with an almost identical design to test this possibility, to replicate results, and to investigate whether the manipulation can, indeed, affect questions (including personality items) towards the end of the study. In addition, to explicitly assess whether making political questions salient impacts mood (Deaton, 2012), we will assess current mood following the primary measures. Finally, to address the unexpected finding that correlations between life satisfaction and relevant criteria were lower in the control condition than the politics-first condition, we will add a fourth condition where the political opinion questions are assessed after the criterion variables. A new preregistration plan will be added to the OSF page linked to above. 
